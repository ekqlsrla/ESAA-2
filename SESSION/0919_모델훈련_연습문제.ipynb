{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekqlsrla/ESAA-2/blob/main/SESSION/0919_%EB%AA%A8%EB%8D%B8%ED%9B%88%EB%A0%A8_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **| 모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10번\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**확률적 경사 하강법**이나 **미니배치 경사하강법**을 사용할 수 있다. 수백만 개의 특성이 있을 때 정규방정식이나 SVD는 속도가 매우 느리기 때문에 사용하기 어렵다. 배치 경사 하강법도 사용이 가능하나 매 스텝에서 전체 훈련 세트를 사용해 그레이디언트를 계산하기 때문에 훈련 세트가 커지면 매우 느려지게 된다."
      ],
      "metadata": {
        "id": "hGUuxPiFGQlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "에포크마다 검증 오차가 일정하게 상승되고 있을 때 훈련 세트에 대한 예측 에러가 상승한다면 이는 모델이 훈련 데이터에 과대적합되기 시작하는 것을 의미한다. 이때는 즉시 훈련을 멈추어야 한다. (P.191)\n",
        "\n",
        "+) 오차에 수렴하는 것이 아니라 발산하고 있는 것이다. 이는 학습률을 낮춰주어 해결해야 한다."
      ],
      "metadata": {
        "id": "SHYECy1OG9DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 오차가 검증 오차와 비슷하고 둘 다 높다면 이는 모델이 훈련 데이터에 과소적합되었다는 것을 의미한다. 따라서 모델의 복잡도는 낮아 분산은 낮고 모델이 제대로 학습되지 못해 높은 편향의 문제가 나타난다. 이때 규제 하이퍼파라미터 α가 증가할수록 모델의 분산은 줄지만 편향은 커지기 때문에(P.185) 반대로 규제하이퍼 파라미터를 감소시켜야 한다."
      ],
      "metadata": {
        "id": "lRznKYSDH2TY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 규제가 없는 모델보다 규제가 **있는** 모델이 성능이 좋아서 릿지 회귀를 사용해야 한다.\n",
        "2. 릿지가 기본이 되지만 **쓰이는 특성이 몇 개뿐**이라고 의심되면 라쏘를 사용하는 것이 낫다. 라쏘 모델은 **불필요한 특성의 가중치를 0**으로 만들어주기 때문이다.\n",
        "3. 특성 수가 훈련 샘플 수 보다 **많거나** 특성 몇 개가 **강하게 연관**되어 있을 때는 보통 라쏘가 문제를 일으키므로 라쏘보다는 엘라스틱넷을 선호한다.\n",
        "\n",
        "P.191"
      ],
      "metadata": {
        "id": "p_V8ReiwJf1p"
      }
    }
  ]
}